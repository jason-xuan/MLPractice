{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "## Classify handwritten digits using the famous MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.csv\n",
    "https://www.kaggle.com/c/digit-recognizer/download/train.csv\n",
    "### test.csv\n",
    "https://www.kaggle.com/c/digit-recognizer/download/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# kelas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "# basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minst = pd.read_csv(\"./Digit Recognizer/train.csv\")\n",
    "\n",
    "def get_df(minst, train_rate=.75):\n",
    "\n",
    "    \n",
    "    minst['is_train'] = np.random.uniform(0, 1, len(minst)) <= train_rate\n",
    "    train, test = minst[minst['is_train']==True], minst[minst['is_train']==False]\n",
    "    \n",
    "    X_label = train.columns[1:-1]\n",
    "    y_label = train.columns[0]\n",
    "    \n",
    "    X_train, y_train = train[X_label], train[y_label]\n",
    "    X_test, y_test = test[X_label], test[y_label]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    return np.array(X_train), y_train, np.array(X_test), y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_df(minst)\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "def network():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, kernel_size[0], kernel_size[1], input_shape = (28,28,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(16, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128, init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, init='uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adadelta\",\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31349 samples, validate on 10651 samples\n",
      "Epoch 1/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.6108 - acc: 0.7937 - val_loss: 0.1429 - val_acc: 0.9565\n",
      "Epoch 2/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.1354 - acc: 0.9566 - val_loss: 0.0952 - val_acc: 0.9722\n",
      "Epoch 3/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.1048 - acc: 0.9663 - val_loss: 0.0798 - val_acc: 0.9757\n",
      "Epoch 4/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0917 - acc: 0.9710 - val_loss: 0.0723 - val_acc: 0.9784\n",
      "Epoch 5/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0790 - acc: 0.9744 - val_loss: 0.0672 - val_acc: 0.9786\n",
      "Epoch 6/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0709 - acc: 0.9774 - val_loss: 0.0598 - val_acc: 0.9825\n",
      "Epoch 7/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0652 - acc: 0.9793 - val_loss: 0.0565 - val_acc: 0.9827\n",
      "Epoch 8/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0590 - acc: 0.9806 - val_loss: 0.0546 - val_acc: 0.9833\n",
      "Epoch 9/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0539 - acc: 0.9819 - val_loss: 0.0541 - val_acc: 0.9839\n",
      "Epoch 10/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0537 - acc: 0.9827 - val_loss: 0.0473 - val_acc: 0.9856\n",
      "Epoch 11/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0495 - acc: 0.9838 - val_loss: 0.0496 - val_acc: 0.9841\n",
      "Epoch 12/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0469 - acc: 0.9846 - val_loss: 0.0481 - val_acc: 0.9850\n",
      "Epoch 13/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0436 - acc: 0.9861 - val_loss: 0.0460 - val_acc: 0.9861\n",
      "Epoch 14/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0417 - acc: 0.9865 - val_loss: 0.0437 - val_acc: 0.9867\n",
      "Epoch 15/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0381 - acc: 0.9874 - val_loss: 0.0439 - val_acc: 0.9866\n",
      "Epoch 16/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0396 - acc: 0.9876 - val_loss: 0.0422 - val_acc: 0.9880\n",
      "Epoch 17/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0356 - acc: 0.9884 - val_loss: 0.0438 - val_acc: 0.9864\n",
      "Epoch 18/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0358 - acc: 0.9885 - val_loss: 0.0463 - val_acc: 0.9857\n",
      "Epoch 19/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0352 - acc: 0.9884 - val_loss: 0.0436 - val_acc: 0.9871\n",
      "Epoch 20/20\n",
      "31349/31349 [==============================] - 7s - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0409 - val_acc: 0.9880\n",
      "10528/10651 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.040939871669025032, 0.98798234907520421]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "nn = network()\n",
    "history = nn.fit(X_train, y_train, nb_epoch=20, batch_size=64, verbose=1, validation_data=(X_test, y_test))\n",
    "nn.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 32)\n",
      "(None, 26, 26, 32)\n",
      "(None, 13, 13, 32)\n",
      "(None, 11, 11, 32)\n",
      "(None, 11, 11, 32)\n",
      "(None, 5, 5, 32)\n",
      "(None, 5, 5, 32)\n",
      "(None, 800)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in nn.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test  = pd.read_csv(\"./Digit Recognizer/test.csv\")\n",
    "_test = np.array(test)\n",
    "_test = _test.reshape(_test.shape[0],28,28,1)\n",
    "result = nn.predict(_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for line in result:\n",
    "    m = np.amax(line)\n",
    "    for i in range(10):\n",
    "        if line[i]==m:\n",
    "            l.append(i)\n",
    "            \n",
    "resu = np.array(l)\n",
    "\n",
    "submit = pd.DataFrame(columns=['ImageId', 'Label'])\n",
    "submit['Label'] = resu\n",
    "submit['ImageId'] = [i for i in range(1, len(resu) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv('./Digit Recognizer/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
