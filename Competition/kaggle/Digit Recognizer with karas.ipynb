{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "## Classify handwritten digits using the famous MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.csv\n",
    "https://www.kaggle.com/c/digit-recognizer/download/train.csv\n",
    "### test.csv\n",
    "https://www.kaggle.com/c/digit-recognizer/download/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kelas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "# basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minst = pd.read_csv(\"./Digit Recognizer/train.csv\")\n",
    "\n",
    "def get_df(minst, train_rate=.75):\n",
    "\n",
    "    \n",
    "    minst['is_train'] = np.random.uniform(0, 1, len(minst)) <= train_rate\n",
    "    train, test = minst[minst['is_train']==True], minst[minst['is_train']==False]\n",
    "    \n",
    "    X_label = train.columns[1:-1]\n",
    "    y_label = train.columns[0]\n",
    "    \n",
    "    X_train, y_train = train[X_label], train[y_label]\n",
    "    X_test, y_test = test[X_label], test[y_label]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    return np.array(X_train), y_train, np.array(X_test), y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_df(minst)\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "def network():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, kernel_size[0], kernel_size[1], input_shape = (28,28,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(16, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128, init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, init='uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adadelta\",\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfb = TensorBoard(log_dir='./logs', histogram_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31368 samples, validate on 10632 samples\n",
      "Epoch 1/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.6300 - acc: 0.7922 - val_loss: 0.1503 - val_acc: 0.9535\n",
      "Epoch 2/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.1511 - acc: 0.9530 - val_loss: 0.1039 - val_acc: 0.9676\n",
      "Epoch 3/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.1167 - acc: 0.9630 - val_loss: 0.0829 - val_acc: 0.9743\n",
      "Epoch 4/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0979 - acc: 0.9697 - val_loss: 0.0901 - val_acc: 0.9711\n",
      "Epoch 5/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0840 - acc: 0.9738 - val_loss: 0.0691 - val_acc: 0.9781\n",
      "Epoch 6/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0771 - acc: 0.9745 - val_loss: 0.0648 - val_acc: 0.9802\n",
      "Epoch 7/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0693 - acc: 0.9784 - val_loss: 0.0607 - val_acc: 0.9812\n",
      "Epoch 8/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0663 - acc: 0.9785 - val_loss: 0.0552 - val_acc: 0.9817\n",
      "Epoch 9/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0609 - acc: 0.9811 - val_loss: 0.0542 - val_acc: 0.9820\n",
      "Epoch 10/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0552 - acc: 0.9823 - val_loss: 0.0546 - val_acc: 0.9833\n",
      "Epoch 11/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0534 - acc: 0.9828 - val_loss: 0.0491 - val_acc: 0.9844\n",
      "Epoch 12/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0514 - acc: 0.9834 - val_loss: 0.0464 - val_acc: 0.9852\n",
      "Epoch 13/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0494 - acc: 0.9842 - val_loss: 0.0471 - val_acc: 0.9847\n",
      "Epoch 14/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0451 - acc: 0.9854 - val_loss: 0.0450 - val_acc: 0.9860\n",
      "Epoch 15/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0418 - acc: 0.9862 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Epoch 16/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0396 - acc: 0.9867 - val_loss: 0.0428 - val_acc: 0.9863\n",
      "Epoch 17/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0409 - acc: 0.9863 - val_loss: 0.0406 - val_acc: 0.9872\n",
      "Epoch 18/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0371 - acc: 0.9876 - val_loss: 0.0409 - val_acc: 0.9871\n",
      "Epoch 19/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0362 - acc: 0.9889 - val_loss: 0.0397 - val_acc: 0.9876\n",
      "Epoch 20/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0339 - acc: 0.9889 - val_loss: 0.0389 - val_acc: 0.9883\n",
      "Epoch 21/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0384 - val_acc: 0.9875\n",
      "Epoch 22/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0320 - acc: 0.9897 - val_loss: 0.0395 - val_acc: 0.9884\n",
      "Epoch 23/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0318 - acc: 0.9903 - val_loss: 0.0410 - val_acc: 0.9876\n",
      "Epoch 24/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0314 - acc: 0.9894 - val_loss: 0.0383 - val_acc: 0.9880\n",
      "Epoch 25/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0307 - acc: 0.9899 - val_loss: 0.0395 - val_acc: 0.9875\n",
      "Epoch 26/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0296 - acc: 0.9909 - val_loss: 0.0402 - val_acc: 0.9877\n",
      "Epoch 27/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0281 - acc: 0.9908 - val_loss: 0.0395 - val_acc: 0.9873\n",
      "Epoch 28/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0382 - val_acc: 0.9882\n",
      "Epoch 29/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0273 - acc: 0.9908 - val_loss: 0.0399 - val_acc: 0.9878\n",
      "Epoch 30/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0376 - val_acc: 0.9879\n",
      "Epoch 31/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0245 - acc: 0.9926 - val_loss: 0.0388 - val_acc: 0.9875\n",
      "Epoch 32/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0243 - acc: 0.9919 - val_loss: 0.0384 - val_acc: 0.9885\n",
      "Epoch 33/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0255 - acc: 0.9916 - val_loss: 0.0380 - val_acc: 0.9892\n",
      "Epoch 34/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0239 - acc: 0.9926 - val_loss: 0.0412 - val_acc: 0.9876\n",
      "Epoch 35/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0220 - acc: 0.9925 - val_loss: 0.0353 - val_acc: 0.9878\n",
      "Epoch 36/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0213 - acc: 0.9928 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "Epoch 37/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0209 - acc: 0.9933 - val_loss: 0.0379 - val_acc: 0.9883\n",
      "Epoch 38/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0207 - acc: 0.9933 - val_loss: 0.0382 - val_acc: 0.9891\n",
      "Epoch 39/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0214 - acc: 0.9925 - val_loss: 0.0398 - val_acc: 0.9889\n",
      "Epoch 40/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0192 - acc: 0.9933 - val_loss: 0.0371 - val_acc: 0.9888\n",
      "Epoch 41/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0189 - acc: 0.9945 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "Epoch 42/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0394 - val_acc: 0.9884\n",
      "Epoch 43/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0386 - val_acc: 0.9886\n",
      "Epoch 44/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0410 - val_acc: 0.9880\n",
      "Epoch 45/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0191 - acc: 0.9939 - val_loss: 0.0387 - val_acc: 0.9885\n",
      "Epoch 46/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0402 - val_acc: 0.9882\n",
      "Epoch 47/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0387 - val_acc: 0.9889\n",
      "Epoch 48/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0167 - acc: 0.9942 - val_loss: 0.0415 - val_acc: 0.9868\n",
      "Epoch 49/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0390 - val_acc: 0.9888\n",
      "Epoch 50/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0434 - val_acc: 0.9872\n",
      "Epoch 51/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0377 - val_acc: 0.9888\n",
      "Epoch 52/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0150 - acc: 0.9948 - val_loss: 0.0384 - val_acc: 0.9888\n",
      "Epoch 53/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0138 - acc: 0.9952 - val_loss: 0.0401 - val_acc: 0.9887\n",
      "Epoch 54/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0373 - val_acc: 0.9896\n",
      "Epoch 55/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0394 - val_acc: 0.9895\n",
      "Epoch 56/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0438 - val_acc: 0.9891\n",
      "Epoch 57/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0420 - val_acc: 0.9890\n",
      "Epoch 58/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0387 - val_acc: 0.9891\n",
      "Epoch 59/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0401 - val_acc: 0.9887\n",
      "Epoch 60/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "Epoch 61/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0402 - val_acc: 0.9889\n",
      "Epoch 62/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0415 - val_acc: 0.9886\n",
      "Epoch 63/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0383 - val_acc: 0.9896\n",
      "Epoch 64/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0119 - acc: 0.9959 - val_loss: 0.0390 - val_acc: 0.9896\n",
      "Epoch 65/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0403 - val_acc: 0.9889\n",
      "Epoch 66/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0126 - acc: 0.9955 - val_loss: 0.0395 - val_acc: 0.9885\n",
      "Epoch 67/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9893\n",
      "Epoch 68/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0399 - val_acc: 0.9892\n",
      "Epoch 69/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0125 - acc: 0.9959 - val_loss: 0.0401 - val_acc: 0.9893\n",
      "Epoch 70/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0416 - val_acc: 0.9894\n",
      "Epoch 71/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0396 - val_acc: 0.9891\n",
      "Epoch 72/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0392 - val_acc: 0.9897\n",
      "Epoch 73/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0122 - acc: 0.9959 - val_loss: 0.0416 - val_acc: 0.9889\n",
      "Epoch 74/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0111 - acc: 0.9960 - val_loss: 0.0409 - val_acc: 0.9902\n",
      "Epoch 75/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0432 - val_acc: 0.9899\n",
      "Epoch 76/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0109 - acc: 0.9961 - val_loss: 0.0427 - val_acc: 0.9898\n",
      "Epoch 77/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0106 - acc: 0.9960 - val_loss: 0.0426 - val_acc: 0.9894\n",
      "Epoch 78/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0415 - val_acc: 0.9892\n",
      "Epoch 79/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0401 - val_acc: 0.9899\n",
      "Epoch 80/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0112 - acc: 0.9965 - val_loss: 0.0404 - val_acc: 0.9891\n",
      "Epoch 81/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0397 - val_acc: 0.9907\n",
      "Epoch 82/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0416 - val_acc: 0.9895\n",
      "Epoch 83/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0426 - val_acc: 0.9894\n",
      "Epoch 84/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0095 - acc: 0.9965 - val_loss: 0.0405 - val_acc: 0.9899\n",
      "Epoch 85/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0429 - val_acc: 0.9900\n",
      "Epoch 86/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0388 - val_acc: 0.9899\n",
      "Epoch 87/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0416 - val_acc: 0.9890\n",
      "Epoch 88/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0411 - val_acc: 0.9889\n",
      "Epoch 89/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0105 - acc: 0.9963 - val_loss: 0.0414 - val_acc: 0.9903\n",
      "Epoch 90/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0418 - val_acc: 0.9893\n",
      "Epoch 91/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0395 - val_acc: 0.9895\n",
      "Epoch 92/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0425 - val_acc: 0.9894\n",
      "Epoch 93/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0088 - acc: 0.9968 - val_loss: 0.0411 - val_acc: 0.9894\n",
      "Epoch 94/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0449 - val_acc: 0.9890\n",
      "Epoch 95/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0431 - val_acc: 0.9895\n",
      "Epoch 96/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0424 - val_acc: 0.9894\n",
      "Epoch 97/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0418 - val_acc: 0.9895\n",
      "Epoch 98/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0408 - val_acc: 0.9903\n",
      "Epoch 99/100\n",
      "31368/31368 [==============================] - 7s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0476 - val_acc: 0.9897\n",
      "Epoch 100/100\n",
      "31368/31368 [==============================] - 8s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0430 - val_acc: 0.9893\n",
      "10464/10632 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.042955163815431241, 0.98927765237020315]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "nn = network()\n",
    "history = nn.fit(X_train, y_train, nb_epoch=100, batch_size=64, verbose=1,callbacks = [tfb], validation_data=(X_test, y_test))\n",
    "nn.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 32)\n",
      "(None, 26, 26, 32)\n",
      "(None, 13, 13, 32)\n",
      "(None, 11, 11, 32)\n",
      "(None, 11, 11, 32)\n",
      "(None, 5, 5, 32)\n",
      "(None, 5, 5, 32)\n",
      "(None, 800)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in nn.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test  = pd.read_csv(\"./Digit Recognizer/test.csv\")\n",
    "_test = np.array(test)\n",
    "_test = _test.reshape(_test.shape[0],28,28,1)\n",
    "result = nn.predict(_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for line in result:\n",
    "    m = np.amax(line)\n",
    "    for i in range(10):\n",
    "        if line[i]==m:\n",
    "            l.append(i)\n",
    "            \n",
    "resu = np.array(l)\n",
    "\n",
    "submit = pd.DataFrame(columns=['ImageId', 'Label'])\n",
    "submit['Label'] = resu\n",
    "submit['ImageId'] = [i for i in range(1, len(resu) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv('./Digit Recognizer/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
